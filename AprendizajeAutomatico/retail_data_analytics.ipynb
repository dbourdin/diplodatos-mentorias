{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Título del Proyecto: Ciencia de Datos aplicada en la Industria Retail\n",
    "\n",
    "## Breve descripción del proyecto (descripción del dataset, problemas interesantes asociados)\n",
    "Se provee de un dataset que contiene datos históricos de ventas correspondientes a 45 tiendas anónimas localizadas en diferentes departamentos. Además el dataset cuenta con información de contexto (temperatura, precio del combustible, tasa de desempleo, información de rebajas, feriados) para las fechas correspondientes a las ventas (ventas registradas semanalmente desde febrero de 2010 hasta noviembre de 2012). Se provee también de una caracterización por tipo y tamaño para cada tienda y una lista de los usuarios que frecuentan cada una.\n",
    "Uno de los desafíos de modelar datos de esta industria se presenta debido a la necesidad de tomar decisiones basadas en operaciones históricas limitadas. Se busca la definición de estrategias y toma de decisiones, en base al análisis y procesamiento de los datos históricos disponibles, para el cumplimiento de un cierto objetivo, como lo puede ser aumento de la rentabilidad del negocio/mejora del servicio prestado al cliente.\n",
    "El objetivo de este proyecto es que el estudiante a lo largo de las materias a cursar en la diplomatura identifique y aplique diferentes técnicas de análisis/procesamiento de los datos que generen información valiosa para un negocio que se desarrolla en la industria en cuestión. Algunos de los puntos interesantes asociados son:\n",
    "- Predicción de ventas futuras (detección de altas y bajas), análisis de estacionalidad de los datos.\n",
    "- Segmentación de las ventas en base a las características de su contexto.\n",
    "- Sistema de recomendación de tiendas para los usuarios.\n",
    "- Análisis del efecto de las rebajas en las ventas para las distintas tiendas.\n",
    "- Análisis del impacto de los feriados en las ventas.\n",
    "- Análisis de correlación entre las diferentes variables provistas y las ventas semanales, análisis del impacto que las mismas causan.\n",
    "\n",
    "## Análisis y Visualización\n",
    "- Correlación entre variables/análisis de independencia. A través de este análisis se puede ver el impacto de cada variable sobre las ventas semanales y de esta manera determinar cuales son las variables importantes a considerar.\n",
    "- Distribución de los ejemplos con respecto a las diferentes clases. \n",
    "- Análisis de outliers.\n",
    "- Visualización de las ventas con respecto al tiempo para cada tienda en un determinado departamento.\n",
    "- Visualización de las ventas totales de cada tienda.\n",
    "- Porcentaje que representan las rebajas sobre las ventas totales para una tienda.\n",
    "\n",
    "## Análisis y Curación\n",
    "Para análisis y curación podrán aplicarse sobre el dataset (en su totalidad) los siguientes puntos:\n",
    "- Importación de datos.\n",
    "- Chequeo de claves únicas por sample/eliminar duplicados.\n",
    "- Despersonalización de datos.\n",
    "- Normalización de los nombres de las columnas en los dataframes.\n",
    "- Tratamiento de valores faltantes.\n",
    "- Codificación de variables categóricas.\n",
    "- Análisis de valores atípicos.\n",
    "- Persistencia de los resultados.\n",
    "- Ordenamiento de las columnas.\n",
    "- Eliminar columnas que no aporten información.\n",
    "- Crear un dataset único de las 3 tablas provistas incluyendo toda la información útil en una misma tabla.\n",
    "\n",
    "## Introducción al ML\n",
    "Los dataset provistos contienen muchas variables sobre las cuales se puede aplicar análisis y procesamiento. En esta materia puntual lo importante es que el estudiante aprenda a hacer la division de los datos, la elección del modelo, evaluación de metricas, independientemente de la complejidad del dataset. Razón por la cual para este práctico se tomaran dos variables simples de analizar, por ejemplo la fecha de las ventas y la columna que nos dice si es feriado o no, y con esto hacer un sistema predictivo en donde se introduce una fecha y el modelo predice si en esa semana hay feriados o no. Con esto podrá aplicarse:\n",
    "- Carga de datos.\n",
    "- Una pequeña reestructuración de las columnas optimizandolo para el análisis que se desea hacer (por ejemplo considerar todas las fechas de la semana y no solo la provista por el dataset).\n",
    "- Division en conjuntos de entrenamiento y evaluación.\n",
    "- Elección de un modelo.\n",
    "- Selección de hyperparámetros.\n",
    "- Métricas sobre el conjunto de evaluación.\n",
    "- Curvas ROC.\n",
    "\n",
    "## Aprendizaje Supervisado\n",
    "En este caso, en la materia se van aplicando diferentes técnicas correspondientes a aprendizaje supervisado evaluando los resultados obtenidos. Lo ideal es partir de un baseline e ir complejizando el modelo. Sería interesante implementar en este caso un sistema predictivo de ventas para un determinado año en base a la información histórica. Se cuenta con features como la fecha (de la que se puede derivar mes o epoca del año), precio del combustible, desempleo, temperatura las cuales se pueden utilizar como entrada de un modelo que prediga las sales que se tendrá en una determinada fecha. Esto podría hacerse como un modelo general, o seleccionar una determinada tienda para hacer el análisis. Se cuenta con el registro de 3 años, la idea sería entrenar el modelo con los dos primeros y testear el comportamiento del modelo con los datos del tercero. Es decir, se entrena con 2010 y 2011, y se corre el modelo con las features del 2012 comparando la salida del predictor con la real.\n",
    "\n",
    "## Aprendizaje No Supervisado\n",
    "Para la aplicación de aprendizaje no supervisado sería interesante hacer dos análisis:\n",
    "- Segmentación de las ventas: clusterizar las ventas junto con las diferentes variables disponibles y hacer un análisis de los grupos obtenidos. Si aplica, evaluar en que caso tenemos las mejores ventas, ante que condiciones, con que combinación de variables. Podría utilizarse un algoritmo como K Means con algún método de optimización de número de clusters como elbow method.\n",
    "- Sistema de recomendación de tiendas: se cuenta con el dato de los usuarios que frecuentan cada tienda, puede armarse un pequeño sistema de recomendación de tiendas a usuarios a través de métodos matriciales.\n",
    "\n",
    "## Optativas Relacionadas\n",
    "Análisis de series temporales, Introducción al data Warehousing, Ciencia de datos en las Finanzas, Introducción al aprendizaje profundo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contenido del Dataset\n",
    "Se provee de datos históricos de ventas de 45 tiendas localizadas en diferentes regiones, cada tienda contiene un número determinado de departamentos. Cada compañía además organiza eventos de rebajas a lo largo del año. Estas rebajas preceden a feriados destacados como lo son: el Super Bowl, el Día del Trabajo, Día de Acción de Gracias y Navidad. Las semanas que incluyen estos feriados tienen un peso 5 veces mayor que las que no.\n",
    "\n",
    "El contenido de los cuatro archivos (Stores, Users, Features y Sales) se presenta a continuación:\n",
    "\n",
    "### Stores\n",
    "Información anónima de las 45 tiendas, incluye tipo y tamaño de las mismas.\n",
    "\n",
    "### Users\n",
    "Lista de usuarios y las tiendas que frecuentan.\n",
    "\n",
    "### Features\n",
    "Contiene información adicional relacionada a las tiendas, la localidad y actividad regional para las fechas dadas.\n",
    "- Store: el número de tienda.\n",
    "- Date: la semana correspondiente.\n",
    "- Temperatura: temperatura promedio de la región.\n",
    "- Fuel Price: costo del combustible en la región.\n",
    "- Markdown 1-5: datos anónimos relacionados a rebajas promocionales. Esta información esta sólo disponible a partir de Noviembre del 2011 y no esta disponible para todas las tiendas todo el tiempo. Lo valores faltantes están marcados como NA.\n",
    "- CPI: índice de precios al consumidor.\n",
    "- Unemployment: tasa de desempleo.\n",
    "- IsHoliday: si la semana contiene al menos un día feriado.\n",
    "\n",
    "### Sales\n",
    "Datos historicos de ventas, cubren desde el 05-02-2010 hasta el 01-11-2012. Incluye los siguientes campos:\n",
    "- Store: el número de tienda.\n",
    "- Dept: el número de departamento.\n",
    "- Date: la fecha correspondiente a la transacción.\n",
    "- Weekly_Sales: ventas para el departamento dado en la tienda correspondiente.\n",
    "- IsHoliday: indica si corresponde a una semana con días feriados o no.\n",
    "\n",
    "Link a la fuente: https://www.kaggle.com/manjeetsingh/retaildataset#Features%20data%20set.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consigna Práctico Introducción ML:\n",
    "En esta materia puntual lo importante es que el estudiante aprenda a hacer la division de los datos, la elección del modelo, evaluación de metricas, independientemente de la complejidad del dataset. Es por esto que se toman para el análisis variables simples del dataset. De esta manera el estudiante puede hacer foco en los conceptos que se desean fijar.\n",
    "\n",
    "Las variables a tratar serán:\n",
    "### Grupo Alpha:\n",
    "- Fecha y columna IsHoliday. El objetivo será construir un predictor que tome la fecha (tratada según criterio de los estudiantes) y prediga si en esa semana hay un feriado o no.\n",
    "\n",
    "### Grupo Omega:\n",
    "- Ventas, IsHoliday y columna IsMarkdown. El objetivo es tomar como entrada el valor de las ventas para una semana y la información de si tiene un día feriado, y predecir si hubo rebajas esa semana.\n",
    "\n",
    "Actividades:\n",
    "1. Importaciones. Seteo de semilla para reproducibilidad. Carga del Dataset. Selección y armado del subconjunto de las variables deseadas.\n",
    "2. División de los datos en conjunto de entrenamiento y test. El conjunto de entrenamiento se utilizará para la creación y selección de los clasificadores. Una vez elegido el model, este set también los servirá para la selección de los hiperparámetros. Una vez entrenado el modelo, se utilizará el conjunto de test (conjunto de datos independiente) para la evaluación del modelo final.\n",
    "3. Elección de un modelo. En este punto se deberán seguir los siguientes pasos:\n",
    "- Selección de hipótesis: elegir la función/modelo que se utilizará para la implementación del clasificador.\n",
    "- Selección del regularizador: analizar si es mejor regularizar con módulo o por cuadrados.\n",
    "- Selección de la función de costo con la cual se va a optimizar el modelo.\n",
    "- Para todos los casos justificar las selecciones.\n",
    "4. Selección de hiperparámetros. Luego de seleccionar y setear el modelo que se utilizará, variar sus hiperparámetros y quedarse con la mejor combinación.\n",
    "5. Evaluación del modelo final. Una vez seleccionados los hiperparámetros y entrenado el modelo, correrlo sobre el conjunto de test/evaluación. Utilizar las métricas que se crean convenientes. Siempre es bueno evaluar con más de una métrica. Que significa la acuracy de un modelo? En que se diferencian Precision y Recall? Cuando es conveniente usar cada una de estas métricas?\n",
    "6. Es el umbral por default el mejor umbral de decisión? En caso contrario, cual es el valor del umbral óptimo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos con la importación del dataset generado a partir del trabajo anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_DIR = os.path.dirname('__file__')\n",
    "DATASET_PATH = os.path.join(CURRENT_DIR, '../datasets')\n",
    "sales_features = pd.read_csv(os.path.join(DATASET_PATH, 'sales_features.csv'), parse_dates=['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos algunos valores para ver que la importación se haya realizado correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Date</th>\n",
       "      <th>Store</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>IsMarkdown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.393782</td>\n",
       "      <td>2010-05-02</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>-0.963798</td>\n",
       "      <td>-1.720834</td>\n",
       "      <td>1.018774</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.524538</td>\n",
       "      <td>2010-05-02</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>-0.963798</td>\n",
       "      <td>-1.720834</td>\n",
       "      <td>1.018774</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.098680</td>\n",
       "      <td>2010-05-02</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>-0.963798</td>\n",
       "      <td>-1.720834</td>\n",
       "      <td>1.018774</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.055551</td>\n",
       "      <td>2010-05-02</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>-0.963798</td>\n",
       "      <td>-1.720834</td>\n",
       "      <td>1.018774</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.715425</td>\n",
       "      <td>2010-05-02</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>-0.963798</td>\n",
       "      <td>-1.720834</td>\n",
       "      <td>1.018774</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Weekly_Sales       Date     Store  Temperature  Fuel_Price  \\\n",
       "0           0      0.393782 2010-05-02 -1.658199    -0.963798   -1.720834   \n",
       "1           1      1.524538 2010-05-02 -1.658199    -0.963798   -1.720834   \n",
       "2           2     -0.098680 2010-05-02 -1.658199    -0.963798   -1.720834   \n",
       "3           3      1.055551 2010-05-02 -1.658199    -0.963798   -1.720834   \n",
       "4           4      0.715425 2010-05-02 -1.658199    -0.963798   -1.720834   \n",
       "\n",
       "        CPI  Unemployment  IsHoliday  IsMarkdown  \n",
       "0  1.018774      0.078201          0           0  \n",
       "1  1.018774      0.078201          0           0  \n",
       "2  1.018774      0.078201          0           0  \n",
       "3  1.018774      0.078201          0           0  \n",
       "4  1.018774      0.078201          0           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_features.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seteamos el valor de la semilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos en conjunto de entrenamiento y evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División entre instancias y etiquetas\n",
    "X, y = sales_features.iloc[:, 1:], sales_features.IsMarkdown\n",
    "\n",
    "# división entre entrenamiento y evaluación\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
