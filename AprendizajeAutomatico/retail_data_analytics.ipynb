{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Título del Proyecto: Ciencia de Datos aplicada en la Industria Retail\n",
    "\n",
    "## Breve descripción del proyecto (descripción del dataset, problemas interesantes asociados)\n",
    "Se provee de un dataset que contiene datos históricos de ventas correspondientes a 45 tiendas anónimas localizadas en diferentes departamentos. Además el dataset cuenta con información de contexto (temperatura, precio del combustible, tasa de desempleo, información de rebajas, feriados) para las fechas correspondientes a las ventas (ventas registradas semanalmente desde febrero de 2010 hasta noviembre de 2012). Se provee también de una caracterización por tipo y tamaño para cada tienda y una lista de los usuarios que frecuentan cada una.\n",
    "Uno de los desafíos de modelar datos de esta industria se presenta debido a la necesidad de tomar decisiones basadas en operaciones históricas limitadas. Se busca la definición de estrategias y toma de decisiones, en base al análisis y procesamiento de los datos históricos disponibles, para el cumplimiento de un cierto objetivo, como lo puede ser aumento de la rentabilidad del negocio/mejora del servicio prestado al cliente.\n",
    "El objetivo de este proyecto es que el estudiante a lo largo de las materias a cursar en la diplomatura identifique y aplique diferentes técnicas de análisis/procesamiento de los datos que generen información valiosa para un negocio que se desarrolla en la industria en cuestión. Algunos de los puntos interesantes asociados son:\n",
    "- Predicción de ventas futuras (detección de altas y bajas), análisis de estacionalidad de los datos.\n",
    "- Segmentación de las ventas en base a las características de su contexto.\n",
    "- Sistema de recomendación de tiendas para los usuarios.\n",
    "- Análisis del efecto de las rebajas en las ventas para las distintas tiendas.\n",
    "- Análisis del impacto de los feriados en las ventas.\n",
    "- Análisis de correlación entre las diferentes variables provistas y las ventas semanales, análisis del impacto que las mismas causan.\n",
    "\n",
    "## Análisis y Visualización\n",
    "- Correlación entre variables/análisis de independencia. A través de este análisis se puede ver el impacto de cada variable sobre las ventas semanales y de esta manera determinar cuales son las variables importantes a considerar.\n",
    "- Distribución de los ejemplos con respecto a las diferentes clases. \n",
    "- Análisis de outliers.\n",
    "- Visualización de las ventas con respecto al tiempo para cada tienda en un determinado departamento.\n",
    "- Visualización de las ventas totales de cada tienda.\n",
    "- Porcentaje que representan las rebajas sobre las ventas totales para una tienda.\n",
    "\n",
    "## Análisis y Curación\n",
    "Para análisis y curación podrán aplicarse sobre el dataset (en su totalidad) los siguientes puntos:\n",
    "- Importación de datos.\n",
    "- Chequeo de claves únicas por sample/eliminar duplicados.\n",
    "- Despersonalización de datos.\n",
    "- Normalización de los nombres de las columnas en los dataframes.\n",
    "- Tratamiento de valores faltantes.\n",
    "- Codificación de variables categóricas.\n",
    "- Análisis de valores atípicos.\n",
    "- Persistencia de los resultados.\n",
    "- Ordenamiento de las columnas.\n",
    "- Eliminar columnas que no aporten información.\n",
    "- Crear un dataset único de las 3 tablas provistas incluyendo toda la información útil en una misma tabla.\n",
    "\n",
    "## Introducción al ML\n",
    "Los dataset provistos contienen muchas variables sobre las cuales se puede aplicar análisis y procesamiento. En esta materia puntual lo importante es que el estudiante aprenda a hacer la division de los datos, la elección del modelo, evaluación de metricas, independientemente de la complejidad del dataset. Razón por la cual para este práctico se tomaran dos variables simples de analizar, por ejemplo la fecha de las ventas y la columna que nos dice si es feriado o no, y con esto hacer un sistema predictivo en donde se introduce una fecha y el modelo predice si en esa semana hay feriados o no. Con esto podrá aplicarse:\n",
    "- Carga de datos.\n",
    "- Una pequeña reestructuración de las columnas optimizandolo para el análisis que se desea hacer (por ejemplo considerar todas las fechas de la semana y no solo la provista por el dataset).\n",
    "- Division en conjuntos de entrenamiento y evaluación.\n",
    "- Elección de un modelo.\n",
    "- Selección de hyperparámetros.\n",
    "- Métricas sobre el conjunto de evaluación.\n",
    "- Curvas ROC.\n",
    "\n",
    "## Aprendizaje Supervisado\n",
    "En este caso, en la materia se van aplicando diferentes técnicas correspondientes a aprendizaje supervisado evaluando los resultados obtenidos. Lo ideal es partir de un baseline e ir complejizando el modelo. Sería interesante implementar en este caso un sistema predictivo de ventas para un determinado año en base a la información histórica. Se cuenta con features como la fecha (de la que se puede derivar mes o epoca del año), precio del combustible, desempleo, temperatura las cuales se pueden utilizar como entrada de un modelo que prediga las sales que se tendrá en una determinada fecha. Esto podría hacerse como un modelo general, o seleccionar una determinada tienda para hacer el análisis. Se cuenta con el registro de 3 años, la idea sería entrenar el modelo con los dos primeros y testear el comportamiento del modelo con los datos del tercero. Es decir, se entrena con 2010 y 2011, y se corre el modelo con las features del 2012 comparando la salida del predictor con la real.\n",
    "\n",
    "## Aprendizaje No Supervisado\n",
    "Para la aplicación de aprendizaje no supervisado sería interesante hacer dos análisis:\n",
    "- Segmentación de las ventas: clusterizar las ventas junto con las diferentes variables disponibles y hacer un análisis de los grupos obtenidos. Si aplica, evaluar en que caso tenemos las mejores ventas, ante que condiciones, con que combinación de variables. Podría utilizarse un algoritmo como K Means con algún método de optimización de número de clusters como elbow method.\n",
    "- Sistema de recomendación de tiendas: se cuenta con el dato de los usuarios que frecuentan cada tienda, puede armarse un pequeño sistema de recomendación de tiendas a usuarios a través de métodos matriciales.\n",
    "\n",
    "## Optativas Relacionadas\n",
    "Análisis de series temporales, Introducción al data Warehousing, Ciencia de datos en las Finanzas, Introducción al aprendizaje profundo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contenido del Dataset\n",
    "Se provee de datos históricos de ventas de 45 tiendas localizadas en diferentes regiones, cada tienda contiene un número determinado de departamentos. Cada compañía además organiza eventos de rebajas a lo largo del año. Estas rebajas preceden a feriados destacados como lo son: el Super Bowl, el Día del Trabajo, Día de Acción de Gracias y Navidad. Las semanas que incluyen estos feriados tienen un peso 5 veces mayor que las que no.\n",
    "\n",
    "El contenido de los cuatro archivos (Stores, Users, Features y Sales) se presenta a continuación:\n",
    "\n",
    "### Stores\n",
    "Información anónima de las 45 tiendas, incluye tipo y tamaño de las mismas.\n",
    "\n",
    "### Users\n",
    "Lista de usuarios y las tiendas que frecuentan.\n",
    "\n",
    "### Features\n",
    "Contiene información adicional relacionada a las tiendas, la localidad y actividad regional para las fechas dadas.\n",
    "- Store: el número de tienda.\n",
    "- Date: la semana correspondiente.\n",
    "- Temperatura: temperatura promedio de la región.\n",
    "- Fuel Price: costo del combustible en la región.\n",
    "- Markdown 1-5: datos anónimos relacionados a rebajas promocionales. Esta información esta sólo disponible a partir de Noviembre del 2011 y no esta disponible para todas las tiendas todo el tiempo. Lo valores faltantes están marcados como NA.\n",
    "- CPI: índice de precios al consumidor.\n",
    "- Unemployment: tasa de desempleo.\n",
    "- IsHoliday: si la semana contiene al menos un día feriado.\n",
    "\n",
    "### Sales\n",
    "Datos historicos de ventas, cubren desde el 05-02-2010 hasta el 01-11-2012. Incluye los siguientes campos:\n",
    "- Store: el número de tienda.\n",
    "- Dept: el número de departamento.\n",
    "- Date: la fecha correspondiente a la transacción.\n",
    "- Weekly_Sales: ventas para el departamento dado en la tienda correspondiente.\n",
    "- IsHoliday: indica si corresponde a una semana con días feriados o no.\n",
    "\n",
    "Link a la fuente: https://www.kaggle.com/manjeetsingh/retaildataset#Features%20data%20set.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consigna Práctico Introducción ML:\n",
    "En esta materia puntual lo importante es que el estudiante aprenda a hacer la division de los datos, la elección del modelo, evaluación de metricas, independientemente de la complejidad del dataset. Es por esto que se toman para el análisis variables simples del dataset. De esta manera el estudiante puede hacer foco en los conceptos que se desean fijar.\n",
    "\n",
    "Las variables a tratar serán:\n",
    "### Grupo Alpha:\n",
    "- Fecha y columna IsHoliday. El objetivo será construir un predictor que tome la fecha (tratada según criterio de los estudiantes) y prediga si en esa semana hay un feriado o no.\n",
    "\n",
    "### Grupo Omega:\n",
    "- Ventas, IsHoliday y columna IsMarkdown. El objetivo es tomar como entrada el valor de las ventas para una semana y la información de si tiene un día feriado, y predecir si hubo rebajas esa semana.\n",
    "\n",
    "Actividades:\n",
    "1. Importaciones. Seteo de semilla para reproducibilidad. Carga del Dataset. Selección y armado del subconjunto de las variables deseadas.\n",
    "2. División de los datos en conjunto de entrenamiento y test. El conjunto de entrenamiento se utilizará para la creación y selección de los clasificadores. Una vez elegido el model, este set también los servirá para la selección de los hiperparámetros. Una vez entrenado el modelo, se utilizará el conjunto de test (conjunto de datos independiente) para la evaluación del modelo final.\n",
    "3. Elección de un modelo. En este punto se deberán seguir los siguientes pasos:\n",
    "- Selección de hipótesis: elegir la función/modelo que se utilizará para la implementación del clasificador.\n",
    "- Selección del regularizador: analizar si es mejor regularizar con módulo o por cuadrados.\n",
    "- Selección de la función de costo con la cual se va a optimizar el modelo.\n",
    "- Para todos los casos justificar las selecciones.\n",
    "4. Selección de hiperparámetros. Luego de seleccionar y setear el modelo que se utilizará, variar sus hiperparámetros y quedarse con la mejor combinación.\n",
    "5. Evaluación del modelo final. Una vez seleccionados los hiperparámetros y entrenado el modelo, correrlo sobre el conjunto de test/evaluación. Utilizar las métricas que se crean convenientes. Siempre es bueno evaluar con más de una métrica. Que significa la acuracy de un modelo? En que se diferencian Precision y Recall? Cuando es conveniente usar cada una de estas métricas?\n",
    "6. Es el umbral por default el mejor umbral de decisión? En caso contrario, cual es el valor del umbral óptimo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import tree\n",
    "from sklearn import linear_model\n",
    "\n",
    "from ml.visualization import plot_confusion_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos con la importación del dataset generado a partir del trabajo anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_DIR = os.path.dirname('__file__')\n",
    "DATASET_PATH = os.path.join(CURRENT_DIR, '../datasets')\n",
    "sales_features = pd.read_csv(os.path.join(DATASET_PATH, 'sales_features.csv'), parse_dates=['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos algunos valores para ver que la importación se haya realizado correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Date</th>\n",
       "      <th>Store</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>IsMarkdown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.393782</td>\n",
       "      <td>2010-05-02</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>-0.963798</td>\n",
       "      <td>-1.720834</td>\n",
       "      <td>1.018774</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.524538</td>\n",
       "      <td>2010-05-02</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>-0.963798</td>\n",
       "      <td>-1.720834</td>\n",
       "      <td>1.018774</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.098680</td>\n",
       "      <td>2010-05-02</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>-0.963798</td>\n",
       "      <td>-1.720834</td>\n",
       "      <td>1.018774</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.055551</td>\n",
       "      <td>2010-05-02</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>-0.963798</td>\n",
       "      <td>-1.720834</td>\n",
       "      <td>1.018774</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.715425</td>\n",
       "      <td>2010-05-02</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>-0.963798</td>\n",
       "      <td>-1.720834</td>\n",
       "      <td>1.018774</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Weekly_Sales       Date     Store  Temperature  Fuel_Price  \\\n",
       "0           0      0.393782 2010-05-02 -1.658199    -0.963798   -1.720834   \n",
       "1           1      1.524538 2010-05-02 -1.658199    -0.963798   -1.720834   \n",
       "2           2     -0.098680 2010-05-02 -1.658199    -0.963798   -1.720834   \n",
       "3           3      1.055551 2010-05-02 -1.658199    -0.963798   -1.720834   \n",
       "4           4      0.715425 2010-05-02 -1.658199    -0.963798   -1.720834   \n",
       "\n",
       "        CPI  Unemployment  IsHoliday  IsMarkdown  \n",
       "0  1.018774      0.078201          0           0  \n",
       "1  1.018774      0.078201          0           0  \n",
       "2  1.018774      0.078201          0           0  \n",
       "3  1.018774      0.078201          0           0  \n",
       "4  1.018774      0.078201          0           0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_features.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos las columnas Year y Week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_row_year_and_week(row):\n",
    "    year, week, day = row.Date.isocalendar()\n",
    "    row['Year'] = year\n",
    "    row['Week'] = week\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sales_features.drop_duplicates(subset=['Date', 'IsHoliday'], inplace=True)\n",
    "sales_features = sales_features.apply(set_row_year_and_week, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Date</th>\n",
       "      <th>Store</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>IsMarkdown</th>\n",
       "      <th>Year</th>\n",
       "      <th>Week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.393782</td>\n",
       "      <td>2010-05-02</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>-0.963798</td>\n",
       "      <td>-1.720834</td>\n",
       "      <td>1.018774</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>1.323501</td>\n",
       "      <td>2010-12-02</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>-1.169783</td>\n",
       "      <td>-1.773177</td>\n",
       "      <td>1.022498</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>145</td>\n",
       "      <td>1.127829</td>\n",
       "      <td>2010-02-19</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>-1.092810</td>\n",
       "      <td>-1.847330</td>\n",
       "      <td>1.023697</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>218</td>\n",
       "      <td>0.150687</td>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>-0.729625</td>\n",
       "      <td>-1.744825</td>\n",
       "      <td>1.024476</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>290</td>\n",
       "      <td>0.257435</td>\n",
       "      <td>2010-05-03</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>-0.736672</td>\n",
       "      <td>-1.605243</td>\n",
       "      <td>1.025255</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>363</td>\n",
       "      <td>0.222892</td>\n",
       "      <td>2010-12-03</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>-0.124679</td>\n",
       "      <td>-1.513643</td>\n",
       "      <td>1.026034</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>436</td>\n",
       "      <td>0.271029</td>\n",
       "      <td>2010-03-19</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>-0.298682</td>\n",
       "      <td>-1.398052</td>\n",
       "      <td>1.021820</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>508</td>\n",
       "      <td>0.451230</td>\n",
       "      <td>2010-03-26</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>-0.468349</td>\n",
       "      <td>-1.371881</td>\n",
       "      <td>1.016774</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>580</td>\n",
       "      <td>1.817484</td>\n",
       "      <td>2010-02-04</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>0.118167</td>\n",
       "      <td>-1.400233</td>\n",
       "      <td>1.011728</td>\n",
       "      <td>-0.081731</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>652</td>\n",
       "      <td>1.187947</td>\n",
       "      <td>2010-09-04</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>0.312769</td>\n",
       "      <td>-1.289004</td>\n",
       "      <td>1.006682</td>\n",
       "      <td>-0.081731</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>725</td>\n",
       "      <td>0.071141</td>\n",
       "      <td>2010-04-16</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>0.337704</td>\n",
       "      <td>-1.206128</td>\n",
       "      <td>1.003257</td>\n",
       "      <td>-0.081731</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>798</td>\n",
       "      <td>0.007225</td>\n",
       "      <td>2010-04-23</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>0.257479</td>\n",
       "      <td>-1.234480</td>\n",
       "      <td>1.001991</td>\n",
       "      <td>-0.081731</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>870</td>\n",
       "      <td>0.025267</td>\n",
       "      <td>2010-04-30</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>0.396790</td>\n",
       "      <td>-1.267195</td>\n",
       "      <td>1.000724</td>\n",
       "      <td>-0.081731</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>941</td>\n",
       "      <td>0.063083</td>\n",
       "      <td>2010-07-05</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>0.675412</td>\n",
       "      <td>-1.147242</td>\n",
       "      <td>0.999458</td>\n",
       "      <td>-0.081731</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>1013</td>\n",
       "      <td>0.129693</td>\n",
       "      <td>2010-05-14</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>0.796293</td>\n",
       "      <td>-1.105804</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>-0.081731</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>1085</td>\n",
       "      <td>-0.053199</td>\n",
       "      <td>2010-05-21</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>0.886276</td>\n",
       "      <td>-1.166871</td>\n",
       "      <td>1.006535</td>\n",
       "      <td>-0.081731</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>1155</td>\n",
       "      <td>-0.017649</td>\n",
       "      <td>2010-05-28</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>1.103103</td>\n",
       "      <td>-1.312995</td>\n",
       "      <td>1.013677</td>\n",
       "      <td>-0.081731</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>1225</td>\n",
       "      <td>0.069430</td>\n",
       "      <td>2010-04-06</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>1.116655</td>\n",
       "      <td>-1.430767</td>\n",
       "      <td>1.020819</td>\n",
       "      <td>-0.081731</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>1296</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>2010-11-06</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>1.102561</td>\n",
       "      <td>-1.511462</td>\n",
       "      <td>1.027961</td>\n",
       "      <td>-0.081731</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>1367</td>\n",
       "      <td>0.010348</td>\n",
       "      <td>2010-06-18</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>1.302041</td>\n",
       "      <td>-1.579072</td>\n",
       "      <td>1.027901</td>\n",
       "      <td>-0.081731</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>1436</td>\n",
       "      <td>0.015299</td>\n",
       "      <td>2010-06-25</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>1.314509</td>\n",
       "      <td>-1.544176</td>\n",
       "      <td>1.024962</td>\n",
       "      <td>-0.081731</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>1505</td>\n",
       "      <td>0.015494</td>\n",
       "      <td>2010-02-07</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>1.128580</td>\n",
       "      <td>-1.509281</td>\n",
       "      <td>1.022022</td>\n",
       "      <td>-0.093001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>1578</td>\n",
       "      <td>0.075183</td>\n",
       "      <td>2010-09-07</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>1.105271</td>\n",
       "      <td>-1.568167</td>\n",
       "      <td>1.019082</td>\n",
       "      <td>-0.093001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>1649</td>\n",
       "      <td>0.051498</td>\n",
       "      <td>2010-07-16</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>1.250003</td>\n",
       "      <td>-1.609605</td>\n",
       "      <td>1.018877</td>\n",
       "      <td>-0.093001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>1719</td>\n",
       "      <td>-0.027335</td>\n",
       "      <td>2010-07-23</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>1.261386</td>\n",
       "      <td>-1.642320</td>\n",
       "      <td>1.022318</td>\n",
       "      <td>-0.093001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>1791</td>\n",
       "      <td>-0.026394</td>\n",
       "      <td>2010-07-30</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>1.178992</td>\n",
       "      <td>-1.572529</td>\n",
       "      <td>1.025760</td>\n",
       "      <td>-0.093001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>1863</td>\n",
       "      <td>0.067242</td>\n",
       "      <td>2010-06-08</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>1.467372</td>\n",
       "      <td>-1.600881</td>\n",
       "      <td>1.029201</td>\n",
       "      <td>-0.093001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933</th>\n",
       "      <td>1933</td>\n",
       "      <td>-0.019588</td>\n",
       "      <td>2010-08-13</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>1.458699</td>\n",
       "      <td>-1.459119</td>\n",
       "      <td>1.032642</td>\n",
       "      <td>-0.093001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>2004</td>\n",
       "      <td>-0.010617</td>\n",
       "      <td>2010-08-20</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>1.439726</td>\n",
       "      <td>-1.520186</td>\n",
       "      <td>1.031721</td>\n",
       "      <td>-0.093001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076</th>\n",
       "      <td>2076</td>\n",
       "      <td>-0.008251</td>\n",
       "      <td>2010-08-27</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>1.362211</td>\n",
       "      <td>-1.618329</td>\n",
       "      <td>1.030801</td>\n",
       "      <td>-0.093001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8102</th>\n",
       "      <td>8102</td>\n",
       "      <td>1.832177</td>\n",
       "      <td>2012-06-04</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>0.560494</td>\n",
       "      <td>1.155850</td>\n",
       "      <td>1.282805</td>\n",
       "      <td>-0.438626</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8174</th>\n",
       "      <td>8174</td>\n",
       "      <td>0.823514</td>\n",
       "      <td>2012-04-13</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>0.486773</td>\n",
       "      <td>1.155850</td>\n",
       "      <td>1.284710</td>\n",
       "      <td>-0.438626</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8245</th>\n",
       "      <td>8245</td>\n",
       "      <td>0.043808</td>\n",
       "      <td>2012-04-20</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>0.361555</td>\n",
       "      <td>1.125317</td>\n",
       "      <td>1.286086</td>\n",
       "      <td>-0.438626</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8316</th>\n",
       "      <td>8316</td>\n",
       "      <td>0.016130</td>\n",
       "      <td>2012-04-27</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>0.387033</td>\n",
       "      <td>0.987916</td>\n",
       "      <td>1.287461</td>\n",
       "      <td>-0.438626</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8387</th>\n",
       "      <td>8387</td>\n",
       "      <td>0.051348</td>\n",
       "      <td>2012-04-05</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>0.838032</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>1.288837</td>\n",
       "      <td>-0.438626</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8458</th>\n",
       "      <td>8458</td>\n",
       "      <td>0.096118</td>\n",
       "      <td>2012-11-05</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>0.741544</td>\n",
       "      <td>0.713116</td>\n",
       "      <td>1.290212</td>\n",
       "      <td>-0.438626</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8529</th>\n",
       "      <td>8529</td>\n",
       "      <td>0.111687</td>\n",
       "      <td>2012-05-18</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>0.555073</td>\n",
       "      <td>0.586620</td>\n",
       "      <td>1.290647</td>\n",
       "      <td>-0.438626</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599</th>\n",
       "      <td>8599</td>\n",
       "      <td>0.043252</td>\n",
       "      <td>2012-05-25</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>0.928557</td>\n",
       "      <td>0.436134</td>\n",
       "      <td>1.290705</td>\n",
       "      <td>-0.438626</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>8670</td>\n",
       "      <td>0.003709</td>\n",
       "      <td>2012-01-06</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>0.968128</td>\n",
       "      <td>0.305276</td>\n",
       "      <td>1.290763</td>\n",
       "      <td>-0.438626</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8741</th>\n",
       "      <td>8741</td>\n",
       "      <td>0.074181</td>\n",
       "      <td>2012-08-06</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>0.987101</td>\n",
       "      <td>0.198409</td>\n",
       "      <td>1.290821</td>\n",
       "      <td>-0.438626</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8813</th>\n",
       "      <td>8813</td>\n",
       "      <td>0.069462</td>\n",
       "      <td>2012-06-15</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>1.044018</td>\n",
       "      <td>0.069733</td>\n",
       "      <td>1.291157</td>\n",
       "      <td>-0.438626</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8884</th>\n",
       "      <td>8884</td>\n",
       "      <td>0.028715</td>\n",
       "      <td>2012-06-22</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>0.991979</td>\n",
       "      <td>-0.032772</td>\n",
       "      <td>1.292188</td>\n",
       "      <td>-0.438626</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8955</th>\n",
       "      <td>8955</td>\n",
       "      <td>-0.011379</td>\n",
       "      <td>2012-06-29</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>1.343781</td>\n",
       "      <td>-0.163630</td>\n",
       "      <td>1.293219</td>\n",
       "      <td>-0.438626</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9024</th>\n",
       "      <td>9024</td>\n",
       "      <td>0.081110</td>\n",
       "      <td>2012-06-07</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>1.164356</td>\n",
       "      <td>-0.292306</td>\n",
       "      <td>1.294250</td>\n",
       "      <td>-0.564747</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9094</th>\n",
       "      <td>9094</td>\n",
       "      <td>0.025755</td>\n",
       "      <td>2012-07-13</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>0.923137</td>\n",
       "      <td>-0.229058</td>\n",
       "      <td>1.295281</td>\n",
       "      <td>-0.564747</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9165</th>\n",
       "      <td>9165</td>\n",
       "      <td>0.016151</td>\n",
       "      <td>2012-07-20</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>1.102019</td>\n",
       "      <td>-0.109106</td>\n",
       "      <td>1.295500</td>\n",
       "      <td>-0.564747</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9237</th>\n",
       "      <td>9237</td>\n",
       "      <td>-0.011011</td>\n",
       "      <td>2012-07-27</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>1.223442</td>\n",
       "      <td>0.100266</td>\n",
       "      <td>1.295719</td>\n",
       "      <td>-0.564747</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9309</th>\n",
       "      <td>9309</td>\n",
       "      <td>0.028490</td>\n",
       "      <td>2012-03-08</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>1.410455</td>\n",
       "      <td>0.122076</td>\n",
       "      <td>1.295938</td>\n",
       "      <td>-0.564747</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9380</th>\n",
       "      <td>9380</td>\n",
       "      <td>0.006105</td>\n",
       "      <td>2012-10-08</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>1.352996</td>\n",
       "      <td>0.290010</td>\n",
       "      <td>1.296156</td>\n",
       "      <td>-0.564747</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9452</th>\n",
       "      <td>9452</td>\n",
       "      <td>0.059418</td>\n",
       "      <td>2012-08-17</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>1.342154</td>\n",
       "      <td>0.457943</td>\n",
       "      <td>1.298199</td>\n",
       "      <td>-0.564747</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9524</th>\n",
       "      <td>9524</td>\n",
       "      <td>0.013436</td>\n",
       "      <td>2012-08-24</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>0.952408</td>\n",
       "      <td>0.564810</td>\n",
       "      <td>1.301609</td>\n",
       "      <td>-0.564747</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9595</th>\n",
       "      <td>9595</td>\n",
       "      <td>0.030777</td>\n",
       "      <td>2012-08-31</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>1.105813</td>\n",
       "      <td>0.604068</td>\n",
       "      <td>1.305019</td>\n",
       "      <td>-0.564747</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9667</th>\n",
       "      <td>9667</td>\n",
       "      <td>0.103082</td>\n",
       "      <td>2012-07-09</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>1.293910</td>\n",
       "      <td>0.804716</td>\n",
       "      <td>1.308429</td>\n",
       "      <td>-0.564747</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9740</th>\n",
       "      <td>9740</td>\n",
       "      <td>0.160052</td>\n",
       "      <td>2012-09-14</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>0.806592</td>\n",
       "      <td>0.776363</td>\n",
       "      <td>1.312081</td>\n",
       "      <td>-0.564747</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9812</th>\n",
       "      <td>9812</td>\n",
       "      <td>0.143993</td>\n",
       "      <td>2012-09-21</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>0.530138</td>\n",
       "      <td>0.785087</td>\n",
       "      <td>1.317184</td>\n",
       "      <td>-0.564747</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9883</th>\n",
       "      <td>9883</td>\n",
       "      <td>0.130621</td>\n",
       "      <td>2012-09-28</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>0.866762</td>\n",
       "      <td>0.665134</td>\n",
       "      <td>1.322286</td>\n",
       "      <td>-0.564747</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9956</th>\n",
       "      <td>9956</td>\n",
       "      <td>0.260806</td>\n",
       "      <td>2012-05-10</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>0.458585</td>\n",
       "      <td>0.558268</td>\n",
       "      <td>1.327389</td>\n",
       "      <td>-0.744536</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10028</th>\n",
       "      <td>10028</td>\n",
       "      <td>0.298653</td>\n",
       "      <td>2012-12-10</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>0.157196</td>\n",
       "      <td>0.523372</td>\n",
       "      <td>1.332492</td>\n",
       "      <td>-0.744536</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10101</th>\n",
       "      <td>10101</td>\n",
       "      <td>0.361233</td>\n",
       "      <td>2012-10-19</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>0.427145</td>\n",
       "      <td>0.508105</td>\n",
       "      <td>1.333626</td>\n",
       "      <td>-0.744536</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10172</th>\n",
       "      <td>10172</td>\n",
       "      <td>0.502377</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>-1.658199</td>\n",
       "      <td>0.491651</td>\n",
       "      <td>0.316181</td>\n",
       "      <td>1.334099</td>\n",
       "      <td>-0.744536</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Weekly_Sales       Date     Store  Temperature  Fuel_Price  \\\n",
       "0               0      0.393782 2010-05-02 -1.658199    -0.963798   -1.720834   \n",
       "73             73      1.323501 2010-12-02 -1.658199    -1.169783   -1.773177   \n",
       "145           145      1.127829 2010-02-19 -1.658199    -1.092810   -1.847330   \n",
       "218           218      0.150687 2010-02-26 -1.658199    -0.729625   -1.744825   \n",
       "290           290      0.257435 2010-05-03 -1.658199    -0.736672   -1.605243   \n",
       "363           363      0.222892 2010-12-03 -1.658199    -0.124679   -1.513643   \n",
       "436           436      0.271029 2010-03-19 -1.658199    -0.298682   -1.398052   \n",
       "508           508      0.451230 2010-03-26 -1.658199    -0.468349   -1.371881   \n",
       "580           580      1.817484 2010-02-04 -1.658199     0.118167   -1.400233   \n",
       "652           652      1.187947 2010-09-04 -1.658199     0.312769   -1.289004   \n",
       "725           725      0.071141 2010-04-16 -1.658199     0.337704   -1.206128   \n",
       "798           798      0.007225 2010-04-23 -1.658199     0.257479   -1.234480   \n",
       "870           870      0.025267 2010-04-30 -1.658199     0.396790   -1.267195   \n",
       "941           941      0.063083 2010-07-05 -1.658199     0.675412   -1.147242   \n",
       "1013         1013      0.129693 2010-05-14 -1.658199     0.796293   -1.105804   \n",
       "1085         1085     -0.053199 2010-05-21 -1.658199     0.886276   -1.166871   \n",
       "1155         1155     -0.017649 2010-05-28 -1.658199     1.103103   -1.312995   \n",
       "1225         1225      0.069430 2010-04-06 -1.658199     1.116655   -1.430767   \n",
       "1296         1296      0.028900 2010-11-06 -1.658199     1.102561   -1.511462   \n",
       "1367         1367      0.010348 2010-06-18 -1.658199     1.302041   -1.579072   \n",
       "1436         1436      0.015299 2010-06-25 -1.658199     1.314509   -1.544176   \n",
       "1505         1505      0.015494 2010-02-07 -1.658199     1.128580   -1.509281   \n",
       "1578         1578      0.075183 2010-09-07 -1.658199     1.105271   -1.568167   \n",
       "1649         1649      0.051498 2010-07-16 -1.658199     1.250003   -1.609605   \n",
       "1719         1719     -0.027335 2010-07-23 -1.658199     1.261386   -1.642320   \n",
       "1791         1791     -0.026394 2010-07-30 -1.658199     1.178992   -1.572529   \n",
       "1863         1863      0.067242 2010-06-08 -1.658199     1.467372   -1.600881   \n",
       "1933         1933     -0.019588 2010-08-13 -1.658199     1.458699   -1.459119   \n",
       "2004         2004     -0.010617 2010-08-20 -1.658199     1.439726   -1.520186   \n",
       "2076         2076     -0.008251 2010-08-27 -1.658199     1.362211   -1.618329   \n",
       "...           ...           ...        ...       ...          ...         ...   \n",
       "8102         8102      1.832177 2012-06-04 -1.658199     0.560494    1.155850   \n",
       "8174         8174      0.823514 2012-04-13 -1.658199     0.486773    1.155850   \n",
       "8245         8245      0.043808 2012-04-20 -1.658199     0.361555    1.125317   \n",
       "8316         8316      0.016130 2012-04-27 -1.658199     0.387033    0.987916   \n",
       "8387         8387      0.051348 2012-04-05 -1.658199     0.838032    0.846154   \n",
       "8458         8458      0.096118 2012-11-05 -1.658199     0.741544    0.713116   \n",
       "8529         8529      0.111687 2012-05-18 -1.658199     0.555073    0.586620   \n",
       "8599         8599      0.043252 2012-05-25 -1.658199     0.928557    0.436134   \n",
       "8670         8670      0.003709 2012-01-06 -1.658199     0.968128    0.305276   \n",
       "8741         8741      0.074181 2012-08-06 -1.658199     0.987101    0.198409   \n",
       "8813         8813      0.069462 2012-06-15 -1.658199     1.044018    0.069733   \n",
       "8884         8884      0.028715 2012-06-22 -1.658199     0.991979   -0.032772   \n",
       "8955         8955     -0.011379 2012-06-29 -1.658199     1.343781   -0.163630   \n",
       "9024         9024      0.081110 2012-06-07 -1.658199     1.164356   -0.292306   \n",
       "9094         9094      0.025755 2012-07-13 -1.658199     0.923137   -0.229058   \n",
       "9165         9165      0.016151 2012-07-20 -1.658199     1.102019   -0.109106   \n",
       "9237         9237     -0.011011 2012-07-27 -1.658199     1.223442    0.100266   \n",
       "9309         9309      0.028490 2012-03-08 -1.658199     1.410455    0.122076   \n",
       "9380         9380      0.006105 2012-10-08 -1.658199     1.352996    0.290010   \n",
       "9452         9452      0.059418 2012-08-17 -1.658199     1.342154    0.457943   \n",
       "9524         9524      0.013436 2012-08-24 -1.658199     0.952408    0.564810   \n",
       "9595         9595      0.030777 2012-08-31 -1.658199     1.105813    0.604068   \n",
       "9667         9667      0.103082 2012-07-09 -1.658199     1.293910    0.804716   \n",
       "9740         9740      0.160052 2012-09-14 -1.658199     0.806592    0.776363   \n",
       "9812         9812      0.143993 2012-09-21 -1.658199     0.530138    0.785087   \n",
       "9883         9883      0.130621 2012-09-28 -1.658199     0.866762    0.665134   \n",
       "9956         9956      0.260806 2012-05-10 -1.658199     0.458585    0.558268   \n",
       "10028       10028      0.298653 2012-12-10 -1.658199     0.157196    0.523372   \n",
       "10101       10101      0.361233 2012-10-19 -1.658199     0.427145    0.508105   \n",
       "10172       10172      0.502377 2012-10-26 -1.658199     0.491651    0.316181   \n",
       "\n",
       "            CPI  Unemployment  IsHoliday  IsMarkdown  Year  Week  \n",
       "0      1.018774      0.078201          0           0  2010    17  \n",
       "73     1.022498      0.078201          1           0  2010    48  \n",
       "145    1.023697      0.078201          0           0  2010     7  \n",
       "218    1.024476      0.078201          0           0  2010     8  \n",
       "290    1.025255      0.078201          0           0  2010    18  \n",
       "363    1.026034      0.078201          0           0  2010    48  \n",
       "436    1.021820      0.078201          0           0  2010    11  \n",
       "508    1.016774      0.078201          0           0  2010    12  \n",
       "580    1.011728     -0.081731          0           0  2010     5  \n",
       "652    1.006682     -0.081731          0           0  2010    35  \n",
       "725    1.003257     -0.081731          0           0  2010    15  \n",
       "798    1.001991     -0.081731          0           0  2010    16  \n",
       "870    1.000724     -0.081731          0           0  2010    17  \n",
       "941    0.999458     -0.081731          0           0  2010    27  \n",
       "1013   0.999394     -0.081731          0           0  2010    19  \n",
       "1085   1.006535     -0.081731          0           0  2010    20  \n",
       "1155   1.013677     -0.081731          0           0  2010    21  \n",
       "1225   1.020819     -0.081731          0           0  2010    14  \n",
       "1296   1.027961     -0.081731          0           0  2010    44  \n",
       "1367   1.027901     -0.081731          0           0  2010    24  \n",
       "1436   1.024962     -0.081731          0           0  2010    25  \n",
       "1505   1.022022     -0.093001          0           0  2010     5  \n",
       "1578   1.019082     -0.093001          0           0  2010    36  \n",
       "1649   1.018877     -0.093001          0           0  2010    28  \n",
       "1719   1.022318     -0.093001          0           0  2010    29  \n",
       "1791   1.025760     -0.093001          0           0  2010    30  \n",
       "1863   1.029201     -0.093001          0           0  2010    23  \n",
       "1933   1.032642     -0.093001          0           0  2010    32  \n",
       "2004   1.031721     -0.093001          0           0  2010    33  \n",
       "2076   1.030801     -0.093001          0           0  2010    34  \n",
       "...         ...           ...        ...         ...   ...   ...  \n",
       "8102   1.282805     -0.438626          0           1  2012    23  \n",
       "8174   1.284710     -0.438626          0           1  2012    15  \n",
       "8245   1.286086     -0.438626          0           1  2012    16  \n",
       "8316   1.287461     -0.438626          0           1  2012    17  \n",
       "8387   1.288837     -0.438626          0           1  2012    14  \n",
       "8458   1.290212     -0.438626          0           1  2012    45  \n",
       "8529   1.290647     -0.438626          0           1  2012    20  \n",
       "8599   1.290705     -0.438626          0           1  2012    21  \n",
       "8670   1.290763     -0.438626          0           1  2012     1  \n",
       "8741   1.290821     -0.438626          0           1  2012    32  \n",
       "8813   1.291157     -0.438626          0           1  2012    24  \n",
       "8884   1.292188     -0.438626          0           1  2012    25  \n",
       "8955   1.293219     -0.438626          0           1  2012    26  \n",
       "9024   1.294250     -0.564747          0           1  2012    23  \n",
       "9094   1.295281     -0.564747          0           1  2012    28  \n",
       "9165   1.295500     -0.564747          0           1  2012    29  \n",
       "9237   1.295719     -0.564747          0           1  2012    30  \n",
       "9309   1.295938     -0.564747          0           1  2012    10  \n",
       "9380   1.296156     -0.564747          0           1  2012    41  \n",
       "9452   1.298199     -0.564747          0           1  2012    33  \n",
       "9524   1.301609     -0.564747          0           1  2012    34  \n",
       "9595   1.305019     -0.564747          0           1  2012    35  \n",
       "9667   1.308429     -0.564747          1           1  2012    28  \n",
       "9740   1.312081     -0.564747          0           1  2012    37  \n",
       "9812   1.317184     -0.564747          0           1  2012    38  \n",
       "9883   1.322286     -0.564747          0           1  2012    39  \n",
       "9956   1.327389     -0.744536          0           1  2012    19  \n",
       "10028  1.332492     -0.744536          0           1  2012    50  \n",
       "10101  1.333626     -0.744536          0           1  2012    42  \n",
       "10172  1.334099     -0.744536          0           1  2012    43  \n",
       "\n",
       "[143 rows x 12 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seteamos el valor de la semilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos en conjunto de entrenamiento y evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División entre instancias y etiquetas\n",
    "X, y = sales_features.iloc[:, 1:], sales_features.IsHoliday\n",
    "\n",
    "# división entre entrenamiento y evaluación\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# La feature del dataset a analizar será \"Week\" \n",
    "feature = 'Week'\n",
    "X_train_feature = X_train[feature].values.reshape(-1, 1)\n",
    "X_test_feature = X_test[feature].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23],\n",
       "       [ 7],\n",
       "       [32],\n",
       "       [26],\n",
       "       [15],\n",
       "       [10],\n",
       "       [19],\n",
       "       [ 7],\n",
       "       [ 6],\n",
       "       [ 4],\n",
       "       [38],\n",
       "       [11],\n",
       "       [46],\n",
       "       [43],\n",
       "       [19],\n",
       "       [10],\n",
       "       [ 3],\n",
       "       [29],\n",
       "       [ 1],\n",
       "       [12],\n",
       "       [18],\n",
       "       [13],\n",
       "       [12],\n",
       "       [26],\n",
       "       [38],\n",
       "       [24],\n",
       "       [27],\n",
       "       [31],\n",
       "       [51],\n",
       "       [15],\n",
       "       [29],\n",
       "       [32],\n",
       "       [20],\n",
       "       [25],\n",
       "       [49],\n",
       "       [13],\n",
       "       [ 8],\n",
       "       [17],\n",
       "       [11],\n",
       "       [21],\n",
       "       [36],\n",
       "       [17],\n",
       "       [42],\n",
       "       [ 8],\n",
       "       [15],\n",
       "       [51],\n",
       "       [16],\n",
       "       [50],\n",
       "       [ 3],\n",
       "       [46],\n",
       "       [ 9],\n",
       "       [48],\n",
       "       [22],\n",
       "       [33],\n",
       "       [47],\n",
       "       [18],\n",
       "       [42],\n",
       "       [14],\n",
       "       [43],\n",
       "       [48],\n",
       "       [44],\n",
       "       [37],\n",
       "       [45],\n",
       "       [17],\n",
       "       [ 1],\n",
       "       [33],\n",
       "       [ 8],\n",
       "       [28],\n",
       "       [32],\n",
       "       [28],\n",
       "       [31],\n",
       "       [40],\n",
       "       [40],\n",
       "       [44],\n",
       "       [24],\n",
       "       [22],\n",
       "       [37],\n",
       "       [41],\n",
       "       [19],\n",
       "       [36],\n",
       "       [24],\n",
       "       [34],\n",
       "       [ 2],\n",
       "       [30],\n",
       "       [52],\n",
       "       [ 6],\n",
       "       [17],\n",
       "       [43],\n",
       "       [49],\n",
       "       [ 9],\n",
       "       [ 1],\n",
       "       [33],\n",
       "       [16],\n",
       "       [25],\n",
       "       [39],\n",
       "       [25],\n",
       "       [30],\n",
       "       [30],\n",
       "       [42],\n",
       "       [34],\n",
       "       [34],\n",
       "       [28],\n",
       "       [19],\n",
       "       [11],\n",
       "       [41],\n",
       "       [40],\n",
       "       [27],\n",
       "       [41],\n",
       "       [ 5],\n",
       "       [35],\n",
       "       [ 4],\n",
       "       [20],\n",
       "       [14],\n",
       "       [52]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.23486545,  0.20233496,  0.04618859, -0.0058602 ,  0.14378007,\n",
       "       -0.0123663 , -0.05790899,  0.13727397, -0.02537849, -0.07742728,\n",
       "        0.21534716,  0.09173128, -0.05790899,  0.15028617,  0.23486545,\n",
       "        0.15679227,  0.15028617,  0.04618859,  0.03968249,  0.09823738,\n",
       "        0.0136581 ,  0.16329837, -0.08393338,  0.05920079,  0.007152  ,\n",
       "        0.19582886,  0.05920079, -0.04489679,  0.17631056])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos inicialmente con modelo de clasificacion lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.LinearRegression()\n",
    "model.fit(X_train_feature, y_train)\n",
    "\n",
    "#print(\"Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\", end=\"\\n\\n\")\n",
    "y_true, y_pred = y_test, model.predict(X_test_feature)\n",
    "#print(classification_report(y_true, y_pred), end=\"\\n\\n\")\n",
    "\n",
    "#plot_confusion_matrix(confusion_matrix(y_true, y_pred),\n",
    "#                          classes=['Paga', 'No paga'], title=\"Matriz de confusión\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.23486545,  0.20233496,  0.04618859, -0.0058602 ,  0.14378007,\n",
       "       -0.0123663 , -0.05790899,  0.13727397, -0.02537849, -0.07742728,\n",
       "        0.21534716,  0.09173128, -0.05790899,  0.15028617,  0.23486545,\n",
       "        0.15679227,  0.15028617,  0.04618859,  0.03968249,  0.09823738,\n",
       "        0.0136581 ,  0.16329837, -0.08393338,  0.05920079,  0.007152  ,\n",
       "        0.19582886,  0.05920079, -0.04489679,  0.17631056])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3228     0\n",
       "8458     0\n",
       "1155     0\n",
       "4016     0\n",
       "1578     0\n",
       "508      0\n",
       "7745     0\n",
       "9595     0\n",
       "9309     0\n",
       "7241     0\n",
       "6731     1\n",
       "9094     0\n",
       "580      0\n",
       "6877     0\n",
       "10028    0\n",
       "2362     0\n",
       "6012     0\n",
       "8599     0\n",
       "8529     0\n",
       "1719     0\n",
       "4519     0\n",
       "6155     0\n",
       "4306     0\n",
       "1863     0\n",
       "4448     0\n",
       "1296     0\n",
       "8102     0\n",
       "7600     0\n",
       "3157     0\n",
       "Name: IsHoliday, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos un modelo de SGDClassifier con cross validation de 5 muestras y realizamos la elección de los parámetros mediante grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luz_4\\Anaconda3\\envs\\diplodatos\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\luz_4\\Anaconda3\\envs\\diplodatos\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Exploración de hiperparámetros para función de coste \"hinge\"\n",
      "\n",
      "Mejor conjunto de parámetros:\n",
      "{'alpha': 0.1, 'eta0': 0.001, 'learning_rate': 'constant'}\n",
      "\n",
      "Puntajes de la grilla:\n",
      "\n",
      "Exactitud: 0.807 (+/-0.047) para los parámetros {'alpha': 0.1, 'eta0': 0.1, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.763 (+/-0.101) para los parámetros {'alpha': 0.1, 'eta0': 0.01, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.921 (+/-0.000) para los parámetros {'alpha': 0.1, 'eta0': 0.001, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.921 (+/-0.000) para los parámetros {'alpha': 0.01, 'eta0': 0.1, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.772 (+/-0.091) para los parámetros {'alpha': 0.01, 'eta0': 0.01, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.921 (+/-0.000) para los parámetros {'alpha': 0.01, 'eta0': 0.001, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.579 (+/-0.171) para los parámetros {'alpha': 0.001, 'eta0': 0.1, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.772 (+/-0.091) para los parámetros {'alpha': 0.001, 'eta0': 0.01, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.921 (+/-0.000) para los parámetros {'alpha': 0.001, 'eta0': 0.001, 'learning_rate': 'constant'}\n",
      "\n",
      "Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        28\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        29\n",
      "   macro avg       0.48      0.50      0.49        29\n",
      "weighted avg       0.93      0.97      0.95        29\n",
      "\n",
      "\n",
      "================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luz_4\\Anaconda3\\envs\\diplodatos\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\luz_4\\Anaconda3\\envs\\diplodatos\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Exploración de hiperparámetros para función de coste \"log\"\n",
      "\n",
      "Mejor conjunto de parámetros:\n",
      "{'alpha': 0.1, 'eta0': 0.1, 'learning_rate': 'constant'}\n",
      "\n",
      "Puntajes de la grilla:\n",
      "\n",
      "Exactitud: 0.921 (+/-0.000) para los parámetros {'alpha': 0.1, 'eta0': 0.1, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.921 (+/-0.000) para los parámetros {'alpha': 0.1, 'eta0': 0.01, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.921 (+/-0.000) para los parámetros {'alpha': 0.1, 'eta0': 0.001, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.763 (+/-0.101) para los parámetros {'alpha': 0.01, 'eta0': 0.1, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.921 (+/-0.000) para los parámetros {'alpha': 0.01, 'eta0': 0.01, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.921 (+/-0.000) para los parámetros {'alpha': 0.01, 'eta0': 0.001, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.921 (+/-0.000) para los parámetros {'alpha': 0.001, 'eta0': 0.1, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.921 (+/-0.000) para los parámetros {'alpha': 0.001, 'eta0': 0.01, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.921 (+/-0.000) para los parámetros {'alpha': 0.001, 'eta0': 0.001, 'learning_rate': 'constant'}\n",
      "\n",
      "Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        28\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        29\n",
      "   macro avg       0.48      0.50      0.49        29\n",
      "weighted avg       0.93      0.97      0.95        29\n",
      "\n",
      "\n",
      "================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luz_4\\Anaconda3\\envs\\diplodatos\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Exploración de hiperparámetros para función de coste \"perceptron\"\n",
      "\n",
      "Mejor conjunto de parámetros:\n",
      "{'alpha': 0.01, 'eta0': 0.1, 'learning_rate': 'constant'}\n",
      "\n",
      "Puntajes de la grilla:\n",
      "\n",
      "Exactitud: 0.754 (+/-0.113) para los parámetros {'alpha': 0.1, 'eta0': 0.1, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.746 (+/-0.117) para los parámetros {'alpha': 0.1, 'eta0': 0.01, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.746 (+/-0.117) para los parámetros {'alpha': 0.1, 'eta0': 0.001, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.921 (+/-0.000) para los parámetros {'alpha': 0.01, 'eta0': 0.1, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.754 (+/-0.113) para los parámetros {'alpha': 0.01, 'eta0': 0.01, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.763 (+/-0.101) para los parámetros {'alpha': 0.01, 'eta0': 0.001, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.921 (+/-0.000) para los parámetros {'alpha': 0.001, 'eta0': 0.1, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.596 (+/-0.161) para los parámetros {'alpha': 0.001, 'eta0': 0.01, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.763 (+/-0.101) para los parámetros {'alpha': 0.001, 'eta0': 0.001, 'learning_rate': 'constant'}\n",
      "\n",
      "Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.04      0.07        28\n",
      "           1       0.04      1.00      0.07         1\n",
      "\n",
      "   micro avg       0.07      0.07      0.07        29\n",
      "   macro avg       0.52      0.52      0.07        29\n",
      "weighted avg       0.97      0.07      0.07        29\n",
      "\n",
      "\n",
      "================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1120x320 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14, 4), dpi= 80, facecolor='w', edgecolor='k')\n",
    "\n",
    "for idx, loss in enumerate(('hinge', 'log', 'perceptron'), start=1):\n",
    "    exploring_params = {\n",
    "        'learning_rate': ['constant'],\n",
    "        'eta0': [0.1, 0.01, 0.001],  # Tasa de entrenamiento\n",
    "        'alpha': [0.1, 0.01, 0.001]  # Tasa de regularización\n",
    "    }\n",
    "    m = SGDClassifier(loss=loss, tol=1e-3)\n",
    "    model = GridSearchCV(m, exploring_params, cv=5, scoring='accuracy')\n",
    "    model.fit(X_train_feature, y_train)\n",
    "    \n",
    "    print(\"# Exploración de hiperparámetros para función de coste \\\"%s\\\"\" % loss, end=\"\\n\\n\")\n",
    "    \n",
    "    print(\"Mejor conjunto de parámetros:\")\n",
    "    print(model.best_params_, end=\"\\n\\n\")\n",
    "\n",
    "    print(\"Puntajes de la grilla:\", end=\"\\n\\n\")\n",
    "    means = model.cv_results_['mean_test_score']\n",
    "    stds = model.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, model.cv_results_['params']):\n",
    "        print(\"Exactitud: %0.3f (+/-%0.03f) para los parámetros %r\" % (mean, std ** 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\", end=\"\\n\\n\")\n",
    "    y_true, y_pred = y_test, model.predict(X_test_feature)\n",
    "    print(classification_report(y_true, y_pred), end=\"\\n\\n\")\n",
    "    \n",
    "    print(\"================================================\", end=\"\\n\\n\")\n",
    "\n",
    "    plt.subplot(1, 3, idx)\n",
    "    plot_confusion_matrix(confusion_matrix(y_true, y_pred),\n",
    "                          classes=['No Feriado', 'Feriado'],\n",
    "                          title=\"Matriz de confusión para %s\" % loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo a los resultados tanto hinge como log son mejores modelos que perceptron para la variable feriado. Pero al tener el dataset tan desbalanceado, al separar el dataset no podemos asegurar que un porcentaje importante de los valores que si son feriados quede en el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos ahora un modelo DecisionTreeClassifier con elección de parametros mediante busqueda por grilla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luz_4\\Anaconda3\\envs\\diplodatos\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\luz_4\\Anaconda3\\envs\\diplodatos\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Exploración de hiperparámetros para función de coste \"gini\"\n",
      "\n",
      "Mejor conjunto de parámetros:\n",
      "{'max_depth': 1, 'min_samples_leaf': 1}\n",
      "\n",
      "Puntajes de la grilla:\n",
      "\n",
      "Exactitud: 0.921 (+/-0.000) para los parámetros {'max_depth': 1, 'min_samples_leaf': 1}\n",
      "Exactitud: 0.921 (+/-0.000) para los parámetros {'max_depth': 1, 'min_samples_leaf': 2}\n",
      "Exactitud: 0.912 (+/-0.001) para los parámetros {'max_depth': 1, 'min_samples_leaf': 3}\n",
      "Exactitud: 0.921 (+/-0.000) para los parámetros {'max_depth': 1, 'min_samples_leaf': 4}\n",
      "Exactitud: 0.921 (+/-0.000) para los parámetros {'max_depth': 1, 'min_samples_leaf': 5}\n",
      "Exactitud: 0.921 (+/-0.002) para los parámetros {'max_depth': 2, 'min_samples_leaf': 1}\n",
      "Exactitud: 0.921 (+/-0.000) para los parámetros {'max_depth': 2, 'min_samples_leaf': 2}\n",
      "Exactitud: 0.886 (+/-0.003) para los parámetros {'max_depth': 2, 'min_samples_leaf': 3}\n",
      "Exactitud: 0.895 (+/-0.003) para los parámetros {'max_depth': 2, 'min_samples_leaf': 4}\n",
      "Exactitud: 0.895 (+/-0.003) para los parámetros {'max_depth': 2, 'min_samples_leaf': 5}\n",
      "Exactitud: 0.904 (+/-0.005) para los parámetros {'max_depth': 3, 'min_samples_leaf': 1}\n",
      "Exactitud: 0.886 (+/-0.003) para los parámetros {'max_depth': 3, 'min_samples_leaf': 2}\n",
      "Exactitud: 0.904 (+/-0.001) para los parámetros {'max_depth': 3, 'min_samples_leaf': 3}\n",
      "Exactitud: 0.895 (+/-0.003) para los parámetros {'max_depth': 3, 'min_samples_leaf': 4}\n",
      "Exactitud: 0.895 (+/-0.003) para los parámetros {'max_depth': 3, 'min_samples_leaf': 5}\n",
      "Exactitud: 0.921 (+/-0.002) para los parámetros {'max_depth': 4, 'min_samples_leaf': 1}\n",
      "Exactitud: 0.904 (+/-0.000) para los parámetros {'max_depth': 4, 'min_samples_leaf': 2}\n",
      "Exactitud: 0.904 (+/-0.001) para los parámetros {'max_depth': 4, 'min_samples_leaf': 3}\n",
      "Exactitud: 0.895 (+/-0.003) para los parámetros {'max_depth': 4, 'min_samples_leaf': 4}\n",
      "Exactitud: 0.895 (+/-0.003) para los parámetros {'max_depth': 4, 'min_samples_leaf': 5}\n",
      "Exactitud: 0.921 (+/-0.002) para los parámetros {'max_depth': 5, 'min_samples_leaf': 1}\n",
      "Exactitud: 0.904 (+/-0.000) para los parámetros {'max_depth': 5, 'min_samples_leaf': 2}\n",
      "Exactitud: 0.904 (+/-0.001) para los parámetros {'max_depth': 5, 'min_samples_leaf': 3}\n",
      "Exactitud: 0.895 (+/-0.003) para los parámetros {'max_depth': 5, 'min_samples_leaf': 4}\n",
      "Exactitud: 0.895 (+/-0.003) para los parámetros {'max_depth': 5, 'min_samples_leaf': 5}\n",
      "Exactitud: 0.912 (+/-0.001) para los parámetros {'max_depth': 6, 'min_samples_leaf': 1}\n",
      "Exactitud: 0.904 (+/-0.000) para los parámetros {'max_depth': 6, 'min_samples_leaf': 2}\n",
      "Exactitud: 0.904 (+/-0.001) para los parámetros {'max_depth': 6, 'min_samples_leaf': 3}\n",
      "Exactitud: 0.895 (+/-0.003) para los parámetros {'max_depth': 6, 'min_samples_leaf': 4}\n",
      "Exactitud: 0.895 (+/-0.003) para los parámetros {'max_depth': 6, 'min_samples_leaf': 5}\n",
      "\n",
      "Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        28\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        29\n",
      "   macro avg       0.48      0.50      0.49        29\n",
      "weighted avg       0.93      0.97      0.95        29\n",
      "\n",
      "\n",
      "================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luz_4\\Anaconda3\\envs\\diplodatos\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\luz_4\\Anaconda3\\envs\\diplodatos\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Exploración de hiperparámetros para función de coste \"entropy\"\n",
      "\n",
      "Mejor conjunto de parámetros:\n",
      "{'max_depth': 1, 'min_samples_leaf': 1}\n",
      "\n",
      "Puntajes de la grilla:\n",
      "\n",
      "Exactitud: 0.921 (+/-0.000) para los parámetros {'max_depth': 1, 'min_samples_leaf': 1}\n",
      "Exactitud: 0.921 (+/-0.000) para los parámetros {'max_depth': 1, 'min_samples_leaf': 2}\n",
      "Exactitud: 0.921 (+/-0.000) para los parámetros {'max_depth': 1, 'min_samples_leaf': 3}\n",
      "Exactitud: 0.921 (+/-0.000) para los parámetros {'max_depth': 1, 'min_samples_leaf': 4}\n",
      "Exactitud: 0.921 (+/-0.000) para los parámetros {'max_depth': 1, 'min_samples_leaf': 5}\n",
      "Exactitud: 0.921 (+/-0.002) para los parámetros {'max_depth': 2, 'min_samples_leaf': 1}\n",
      "Exactitud: 0.921 (+/-0.000) para los parámetros {'max_depth': 2, 'min_samples_leaf': 2}\n",
      "Exactitud: 0.886 (+/-0.003) para los parámetros {'max_depth': 2, 'min_samples_leaf': 3}\n",
      "Exactitud: 0.895 (+/-0.003) para los parámetros {'max_depth': 2, 'min_samples_leaf': 4}\n",
      "Exactitud: 0.895 (+/-0.003) para los parámetros {'max_depth': 2, 'min_samples_leaf': 5}\n",
      "Exactitud: 0.904 (+/-0.005) para los parámetros {'max_depth': 3, 'min_samples_leaf': 1}\n",
      "Exactitud: 0.895 (+/-0.003) para los parámetros {'max_depth': 3, 'min_samples_leaf': 2}\n",
      "Exactitud: 0.904 (+/-0.001) para los parámetros {'max_depth': 3, 'min_samples_leaf': 3}\n",
      "Exactitud: 0.895 (+/-0.003) para los parámetros {'max_depth': 3, 'min_samples_leaf': 4}\n",
      "Exactitud: 0.895 (+/-0.003) para los parámetros {'max_depth': 3, 'min_samples_leaf': 5}\n",
      "Exactitud: 0.921 (+/-0.002) para los parámetros {'max_depth': 4, 'min_samples_leaf': 1}\n",
      "Exactitud: 0.904 (+/-0.000) para los parámetros {'max_depth': 4, 'min_samples_leaf': 2}\n",
      "Exactitud: 0.904 (+/-0.001) para los parámetros {'max_depth': 4, 'min_samples_leaf': 3}\n",
      "Exactitud: 0.895 (+/-0.003) para los parámetros {'max_depth': 4, 'min_samples_leaf': 4}\n",
      "Exactitud: 0.895 (+/-0.003) para los parámetros {'max_depth': 4, 'min_samples_leaf': 5}\n",
      "Exactitud: 0.921 (+/-0.002) para los parámetros {'max_depth': 5, 'min_samples_leaf': 1}\n",
      "Exactitud: 0.904 (+/-0.000) para los parámetros {'max_depth': 5, 'min_samples_leaf': 2}\n",
      "Exactitud: 0.904 (+/-0.001) para los parámetros {'max_depth': 5, 'min_samples_leaf': 3}\n",
      "Exactitud: 0.895 (+/-0.003) para los parámetros {'max_depth': 5, 'min_samples_leaf': 4}\n",
      "Exactitud: 0.895 (+/-0.003) para los parámetros {'max_depth': 5, 'min_samples_leaf': 5}\n",
      "Exactitud: 0.921 (+/-0.002) para los parámetros {'max_depth': 6, 'min_samples_leaf': 1}\n",
      "Exactitud: 0.904 (+/-0.000) para los parámetros {'max_depth': 6, 'min_samples_leaf': 2}\n",
      "Exactitud: 0.904 (+/-0.001) para los parámetros {'max_depth': 6, 'min_samples_leaf': 3}\n",
      "Exactitud: 0.895 (+/-0.003) para los parámetros {'max_depth': 6, 'min_samples_leaf': 4}\n",
      "Exactitud: 0.895 (+/-0.003) para los parámetros {'max_depth': 6, 'min_samples_leaf': 5}\n",
      "\n",
      "Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        28\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        29\n",
      "   macro avg       0.48      0.50      0.49        29\n",
      "weighted avg       0.93      0.97      0.95        29\n",
      "\n",
      "\n",
      "================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1120x320 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14, 4), dpi= 80, facecolor='w', edgecolor='k')\n",
    "\n",
    "for idx, criterion in enumerate(('gini', 'entropy'), start=1):\n",
    "    exploring_params = {\n",
    "        'max_depth': [1,2,3,4,5,6],\n",
    "        'min_samples_leaf': [1,2,3,4,5],  #\n",
    "    }\n",
    "    m = tree.DecisionTreeClassifier(criterion=criterion) \n",
    "    model = GridSearchCV(m, exploring_params, cv=5, scoring='accuracy')\n",
    "    model.fit(X_train_feature, y_train)\n",
    "    \n",
    "    print(\"# Exploración de hiperparámetros para función de coste \\\"%s\\\"\" % criterion, end=\"\\n\\n\")\n",
    "    \n",
    "    print(\"Mejor conjunto de parámetros:\")\n",
    "    print(model.best_params_, end=\"\\n\\n\")\n",
    "\n",
    "    print(\"Puntajes de la grilla:\", end=\"\\n\\n\")\n",
    "    means = model.cv_results_['mean_test_score']\n",
    "    stds = model.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, model.cv_results_['params']):\n",
    "        print(\"Exactitud: %0.3f (+/-%0.03f) para los parámetros %r\" % (mean, std ** 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\", end=\"\\n\\n\")\n",
    "    y_true, y_pred = y_test, model.predict(X_test_feature)\n",
    "    print(classification_report(y_true, y_pred), end=\"\\n\\n\")\n",
    "    \n",
    "    \n",
    "    print(\"================================================\", end=\"\\n\\n\")\n",
    "\n",
    "    plt.subplot(1, 3, idx)\n",
    "    plot_confusion_matrix(confusion_matrix(y_true, y_pred),\n",
    "                          classes=['No Feriado', 'Feriado'], title=\"Matriz de confusión para %s\" % criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este caso los modelos de árbol de desicion arrojan resultados similares que los modelos anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que significa la acuracy de un modelo? En que se diferencian Precision y Recall? Cuando es conveniente usar cada una de estas métricas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Acuracy de un modelo**: es el porcentaje de los datos correctamente predichos por el modelo: para el caso de un problema de dos clases seria la suma de los valores positivos predicchos correctamente por el modelo (true positives) mas los valores negativos predichos correctamente por el modelo sobre el total de los datos. No es una medida muy útil para el caso de que exista un gran sesgo de clase o si existieran diferentes costos de clasificar mal las diferentes clases.\n",
    "\n",
    "**Precision**: mide qué porcentaje de todos las observaciones clasificadas como positivas por el modelo correspondian a clases positivas en la realidad. Es el porcentaje de aciertos para una determinada clase.\n",
    "\n",
    "**Recall**: mide el porcentaje de positivos clasificados como tal por el modelo, es decir de todos los positivos o de clase I, qué porcentaje es el que el modelo clasifica bien de dicha clase."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
